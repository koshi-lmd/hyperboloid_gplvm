{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d1478c-41d8-4061-88a2-1242df5cea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo code of hyperboloid GP-LVM\n",
    "# Our source code does not require any GPU dependency.\n",
    "# Our code depends on numpy, scipy, and tqdm.\n",
    "\n",
    "# python:3.10.12, numpy: 1.26.2, scipy: 1.11.4, tqdm: 4.66.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eedf102-5f42-460a-b5e7-718e1fe95a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import library and modules\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from hyperboloid_gplvm import HyperboloidGPLVM\n",
    "from sparse_hyperboloid_gplvm import SparseHyperboloidGPLVM\n",
    "from bayesian_hyperboloid_gplvm import BayesianHyperboloidGPLVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89b44f2-1dd0-4903-b3bb-2550d35714cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function for scatter plot on the Poincare ball\n",
    "# We use the code presented in the PoincareMap implementation (https://www.nature.com/articles/s41467-020-16822-4)\n",
    "# We appreciate their contribution.\n",
    "\n",
    "def linear_scale(embeddings):\n",
    "    embeddings = np.transpose(embeddings)\n",
    "    sqnorm = np.sum(embeddings ** 2, axis=1, keepdims=True)\n",
    "    dist = np.arccosh(1 + 2 * sqnorm / (1 - sqnorm))\n",
    "    dist = np.sqrt(dist)\n",
    "    dist /= dist.max()\n",
    "    sqnorm[sqnorm == 0] = 1\n",
    "    embeddings = dist * embeddings / np.sqrt(sqnorm)\n",
    "    return np.transpose(embeddings)\n",
    "\n",
    "def plotPoincareDisc(x,\n",
    "                     label_names=None,\n",
    "                     file_name=None,\n",
    "                     title_name=None,\n",
    "                     idx_zoom=None,\n",
    "                     show=False,\n",
    "                     d1=12,\n",
    "                     d2=6,\n",
    "                     fs=11,\n",
    "                     ms=4,\n",
    "                     col_palette=None,\n",
    "                     color_dict=None,\n",
    "                     legend=True):\n",
    "    if col_palette is None:\n",
    "        # col_palette = colors_palette\n",
    "        # col_palette = plt.get_cmap(\"tab10\")\n",
    "        col_palette = sns.color_palette('deep')\n",
    "\n",
    "    df = pd.DataFrame(dict(x=x[0], y=x[1], label=label_names))\n",
    "    groups = df.groupby('label')\n",
    "\n",
    "    fig = plt.figure(figsize=(d1, d2), dpi=300)\n",
    "    circle = plt.Circle((0, 0), radius=1,  fc='none', color='black')\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.gca().add_patch(circle)\n",
    "    plt.plot(0, 0, 'x', c=(0, 0, 0), ms=ms)\n",
    "    plt.title(title_name, fontsize=fs)\n",
    "\n",
    "    if color_dict is None:\n",
    "        j = 0\n",
    "        color_dict = {}\n",
    "        for name, group in groups:\n",
    "            color_dict[name] = col_palette[j]\n",
    "            j += 1\n",
    "\n",
    "    marker = '.'\n",
    "    for name, group in groups:        \n",
    "        plt.plot(group.x, group.y, marker=marker, markerfacecolor='none',\n",
    "                 c=color_dict[name], linestyle='', ms=ms, label=name)\n",
    "    plt.plot(0, 0, 'x', c=(0, 0, 0), ms=ms)\n",
    "    plt.axis('off')\n",
    "    plt.axis('equal')\n",
    "    # plt.legend(numpoints=1, loc='center left',\n",
    "    #            bbox_to_anchor=(1, 0.5), fontsize=fs)\n",
    "\n",
    "    labels_list = np.unique(label_names)\n",
    "#\n",
    "    if idx_zoom is None:\n",
    "        xl = np.array(linear_scale(x))\n",
    "        xl[np.isnan(xl)] = 0\n",
    "\n",
    "        df = pd.DataFrame(dict(x=xl[0], y=xl[1], label=label_names))\n",
    "        groups = df.groupby('label')\n",
    "    else:\n",
    "        xl = np.array(linear_scale(x[:, idx_zoom]))\n",
    "        xl[np.isnan(xl)] = 0\n",
    "\n",
    "        df = pd.DataFrame(dict(x=xl[0], y=xl[1], label=label_names[idx_zoom]))\n",
    "        groups = df.groupby('label')\n",
    "\n",
    "    circle = plt.Circle((0, 0), radius=1, fc='none',\n",
    "                        color='black', linestyle=':')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.gca().add_patch(circle)\n",
    "    # plt.plot(0, 0, 'x', c=(0, 0, 0), ms=ms)\n",
    "    plt.title('zoom in', fontsize=fs)\n",
    "    marker = 'o'\n",
    "    for name, group in groups:\n",
    "        plt.plot(group.x, group.y, marker=marker, markerfacecolor='none',\n",
    "                 c=color_dict[name], linestyle='', ms=ms, label=name)\n",
    "\n",
    "    plt.plot(0, 0, 'x', c=(0, 0, 0), ms=ms)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.axis('equal')\n",
    "\n",
    "#     for l in labels_list:\n",
    "# #         i = np.random.choice(np.where(labels == l)[0])\n",
    "#         ix_l = np.where(label_names == l)[0]\n",
    "#         c1 = np.median(xl[0, ix_l])\n",
    "#         c2 = np.median(xl[1, ix_l])\n",
    "#         plt.text(c1, c2, l, fontsize=fs)\n",
    "    if legend:\n",
    "        plt.legend(numpoints=1, loc='center left',\n",
    "               bbox_to_anchor=(1, 0.5), fontsize=fs)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if file_name:\n",
    "        plt.savefig(file_name + '.svg', format='svg')\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "def diffeomorphism2ball(X):\n",
    "    \"\"\"\n",
    "    diffeomorphism from hyperboloid to Poincare ball\n",
    "    \"\"\"\n",
    "    return X[:,1:] / (X[:,0][:,None] + 1.)\n",
    "\n",
    "def return_embedding(model, model_name):\n",
    "    if model_name == 'hgplvm' or model_name == 'sparse_hgplvm':\n",
    "        return diffeomorphism2ball(model.X)\n",
    "    else:\n",
    "        return diffeomorphism2ball(model.M)\n",
    "\n",
    "def return_raw_embedding(model, model_name):\n",
    "    if model_name == 'hgplvm' or model_name == 'sparse_hgplvm':\n",
    "        return diffeomorphism2ball(model.X)\n",
    "    else:\n",
    "        return diffeomorphism2ball(model.M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6af7e64-d87d-4c45-b79f-f5f44f66fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function for model and data load\n",
    "\n",
    "def return_model(model, data, lengthscale, num_inducing=None, sampling_num=None):\n",
    "    if model == 'hgplvm':\n",
    "        return HyperboloidGPLVM(Y=data, latent_dim=2, lengthscale=lengthscale)\n",
    "    elif model == 'sparse_hgplvm':\n",
    "        return SparseHyperboloidGPLVM(Y=data, latent_dim=2, lengthscale=lengthscale, num_inducing=num_inducing)\n",
    "    elif model == 'bayesian_hgplvm':\n",
    "        return BayesianHyperboloidGPLVM(Y=data, latent_dim=2, lengthscale=lengthscale, num_inducing=num_inducing, sampling_num=sampling_num)\n",
    "\n",
    "def load_data(data_name):\n",
    "    data = np.load('dataset/%s/train/data.npy'%(data_name))\n",
    "    label = np.load('dataset/%s/train/label.npy'%(data_name), allow_pickle=True).reshape(-1)[:]\n",
    "    is_file = os.path.isfile('dataset/%s/train/label_name.npy'%(data_name))\n",
    "    if is_file:\n",
    "        label = np.load('dataset/%s/train/label_name.npy'%(data_name), allow_pickle=True).reshape(-1)[:]\n",
    "    return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e03709c-e0bf-480b-8e87-b2345ceac19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select dataset from ['MyeloidProgenitors', 'Paul'(scRNA-seq), 'synthetic_bin_tree/4','synthetic_bin_tree/5','synthetic_bin_tree/6']\n",
    "# ('synthetic_bin_tree/4' means synthetic binary tree dataset with depth 4.)\n",
    "data_name = 'synthetic_bin_tree/5'\n",
    "\n",
    "# Color code for Paul dataset (from PoincareMap implementation)\n",
    "color_dict_paul = {'12Baso': '#0570b0', '13Baso': '#034e7b',\n",
    "\t '11DC': '#ffff33', \n",
    "\t '18Eos': '#2CA02C', \n",
    "\t '1Ery': '#fed976', '2Ery': '#feb24c', '3Ery': '#fd8d3c', '4Ery': '#fc4e2a', '5Ery': '#e31a1c', '6Ery': '#b10026',\n",
    "\t '9GMP': '#999999', '10GMP': '#4d4d4d',\n",
    "\t '19Lymph': '#35978f', \n",
    "\t '7MEP': '#E377C2', \n",
    "\t '8Mk': '#BCBD22', \n",
    "\t '14Mo': '#4eb3d3', '15Mo': '#7bccc4',\n",
    "\t '16Neu': '#6a51a3','17Neu': '#3f007d',\n",
    "\t 'root': '#000000'}\n",
    "\n",
    "# Define model and hyperparameter\n",
    "# We recommend hgplvm for synthetic data and Bayesian hgplbm for scRNA-seq data (but time consuming)\n",
    "\n",
    "# select model ['hgplvm', 'sparse_hgplvm', 'bayesian_hgplvm']\n",
    "# Bayesian hGP-LVM is slow due to the sampling approximation. \n",
    "model_name = 'hgplvm'\n",
    "\n",
    "# set lengthscale (we recommend 'lengthscale=100')\n",
    "lengthscale=100\n",
    "\n",
    "# set num_inducing M (sparse and Bayesian hGP-LVM) and number of the sampling (Bayesian hGP-LVM)\n",
    "num_inducing = 50\n",
    "sampling_num = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa677cb-da78-41b4-be47-ebb9c2d02703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf0001b37364686abda9393a4263f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th iter: mean norm:0.01858, obj:18265.11566\n",
      "10-th iter: mean norm:0.25697, obj:17240.53957\n",
      "20-th iter: mean norm:0.22452, obj:16120.48083\n",
      "30-th iter: mean norm:0.21768, obj:14857.12891\n",
      "40-th iter: mean norm:0.21135, obj:13404.62709\n",
      "50-th iter: mean norm:0.21666, obj:11696.58300\n",
      "60-th iter: mean norm:0.21958, obj:9620.00956\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Learning hGP-LVMs\n",
    "data, label = load_data(data_name)\n",
    "model = return_model(model_name, data, lengthscale, num_inducing, sampling_num)\n",
    "\n",
    "color_dict = None\n",
    "if data_name=='Paul':\n",
    "    color_dict = color_dict_paul\n",
    "if 'synthesis_bin_tree' in data_name:\n",
    "    y_set = set(label)\n",
    "    colors_palette = sns.color_palette(\"deep\",len(y_set))\n",
    "\n",
    "# We recommend 'max_iters=1500' for Bayesian hGP-LVM on Paul dataset\n",
    "model.RiemannGD(max_iters=1500)\n",
    "embedding = return_embedding(model, model_name)\n",
    "title = model_name + '_' + 'lengthscale_' + str(lengthscale)\n",
    "\n",
    "plotPoincareDisc(embedding.T, label, file_name=title, title_name=title, show=True, color_dict=color_dict, legend=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ccfe0a7-b071-4a0d-9c96-c8416dfbc6b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/MyeloidProgenitors/train/true_data.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhyperboloid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hyperboloid\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# binary representation of data\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m true_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset/\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m/train/true_data.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# compute hamming distance\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# We use the implementation presented in \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# https://proceedings.neurips.cc/paper_files/paper/2022/file/71ad539a57b1fd49b19e5c80070cb8b9-Paper-Conference.pdf \u001b[39;00m\n\u001b[1;32m     12\u001b[0m d_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((true_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],true_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/MyeloidProgenitors/train/true_data.npy'"
     ]
    }
   ],
   "source": [
    "# quantitative evaluation for bin_tree data\n",
    "\n",
    "from hyperboloid import Hyperboloid\n",
    "\n",
    "# binary representation of data\n",
    "true_data = np.load('dataset/%s/train/true_data.npy'%(data_name))\n",
    "\n",
    "# compute hamming distance\n",
    "# We use the implementation presented in \n",
    "# https://proceedings.neurips.cc/paper_files/paper/2022/file/71ad539a57b1fd49b19e5c80070cb8b9-Paper-Conference.pdf \n",
    "\n",
    "d_true = np.zeros((true_data.shape[0],true_data.shape[0]))\n",
    "for i in range(d_true.shape[0]):\n",
    "    for j in range(d_true.shape[1]):\n",
    "        d_true[i][j] = (true_data[i].astype(np.int32) ^ true_data[j].astype(np.int32)).sum()\n",
    "\n",
    "comp = Hyperboloid(2)\n",
    "d_embedding = comp.distance(model.X)\n",
    "mask = np.fromfunction(lambda i, j: i > j, shape=d_true.shape)\n",
    "corr_distance = np.corrcoef(d_embedding[mask].ravel(), d_true[mask].ravel())[0, 1]\n",
    "\n",
    "print(corr_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fbd369-11c1-46f0-8c25-5897f17790fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
